{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to train UNet with L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image\n",
    "!pip install IProgress\n",
    "!pip install jupyter\n",
    "!pip install ipywidgets widgetsnbextension pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from python.data.dataset import *\n",
    "from python.models.generator import UNet\n",
    "from python.models.discriminator import PatchGAN\n",
    "from python.utils.images import *\n",
    "from python.train.trainer import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "SEED = 42\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "log = open(\"train.log\", \"a\")\n",
    "sys.stdout = log\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/datasets/coco\"\n",
    "version = \"2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(m): # https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py\n",
    "    classname = m.__class__.__name__\n",
    "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        \n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "            \n",
    "    elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "dataset_train = CocoLab(dataset, version=version, size=256, train=True)\n",
    "trainloader = data.DataLoader(dataset_train, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_test = CocoLab(dataset, version=version, size=256, train=False)\n",
    "testloader = data.DataLoader(dataset_test, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "generator = UNet(1, 2).to(device)\n",
    "discriminator = PatchGAN(3).to(device)\n",
    "\n",
    "generator.apply(init_weight) # init weights with a gaussian distribution centered at 0, and std=0.02\n",
    "discriminator.apply(init_weight) # init weights with a gaussian distribution centered at 0, and std=0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "gan_train = GanTrain(generator, discriminator)\n",
    "\n",
    "train_g_avg_loss = []\n",
    "train_d_avg_loss = []\n",
    "test_g_avg_loss = []\n",
    "test_d_avg_loss = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_g_losses = []\n",
    "    train_d_losses = []\n",
    "    test_g_losses = []\n",
    "    test_d_losses = []\n",
    "    \n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for L, ab in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            L = L.to(device)\n",
    "            ab = ab.to(device)\n",
    "\n",
    "            d_loss, g_loss = gan_train.step(L, ab)\n",
    "\n",
    "            train_g_losses.append(g_loss.detach().to(\"cpu\"))\n",
    "            train_d_losses.append(d_loss.detach().to(\"cpu\"))  \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            # Do not set .eval()\n",
    "            for L, ab in testloader:\n",
    "                L = L.to(device)\n",
    "                ab = ab.to(device)\n",
    "                fake_ab = generator(L)\n",
    "                g_loss = gan_train.generator_loss(L, ab, fake_ab)\n",
    "                d_loss = gan_train.discriminator_loss(L, ab, fake_ab)\n",
    "                \n",
    "                test_g_losses.append(g_loss.detach().to(\"cpu\"))\n",
    "                test_d_losses.append(d_loss.detach().to(\"cpu\"))\n",
    "\n",
    "            train_g_avg_loss.append(torch.mean(torch.Tensor(train_g_losses)).to(\"cpu\"))\n",
    "            train_d_avg_loss.append(torch.mean(torch.Tensor(train_d_losses)).to(\"cpu\"))\n",
    "            test_g_avg_loss.append(torch.mean(torch.Tensor(test_g_losses)).to(\"cpu\"))\n",
    "            test_d_avg_loss.append(torch.mean(torch.Tensor(test_d_losses)).to(\"cpu\"))\n",
    "\n",
    "            print('[Epoch {}/{}] '.format(epoch+1, num_epochs) + \"\\n--- Generator ---\\n\" +\n",
    "                    '\\ttrain_loss: {:.4f} - '.format(train_g_avg_loss[-1]) +\n",
    "                    'test_loss: {:.4f} - '.format(test_g_avg_loss[-1]) + \"\\n--- Discriminator ---\\n\" +\n",
    "                    '\\ttrain_loss: {:.4f} - '.format(train_d_avg_loss[-1]) +\n",
    "                    'test_loss: {:.4f}'.format(test_d_avg_loss[-1]))\n",
    "\n",
    "            multi_plot(testloader, generator, \"figures/epoch_{}.png\".format(epoch+1), columns=4)\n",
    "            torch.save(generator.state_dict(), \"saved_models/generator\")\n",
    "        \n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('Generator losses')\n",
    "plt.plot(train_g_avg_loss)\n",
    "plt.plot(test_g_avg_loss)\n",
    "plt.grid()\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig(\"figures/generator_losses.png\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('Discriminator losses')\n",
    "plt.plot(train_d_avg_loss)\n",
    "plt.plot(test_d_avg_loss)\n",
    "plt.grid()\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig(\"figures/discriminator_losses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0002\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    generator.train()\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for L, ab in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            L = L.to(device)\n",
    "            ab = ab.to(device)\n",
    "\n",
    "            pred = generator(L)\n",
    "            loss = criterion(pred, ab)\n",
    "\n",
    "            train_losses.append(loss.detach())\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():   \n",
    "            generator.eval()\n",
    "\n",
    "            for L, ab in testloader:\n",
    "                L = L.to(device)\n",
    "                ab = ab.to(device)\n",
    "\n",
    "                pred = generator(L)\n",
    "                loss = criterion(pred, ab)\n",
    "                test_losses.append(loss.detach())\n",
    "\n",
    "            train_avg_loss.append(torch.mean(torch.Tensor(train_losses)))\n",
    "            test_avg_loss.append(torch.mean(torch.Tensor(test_losses)))\n",
    "\n",
    "            print('[Epoch {}/{}] '.format(epoch+1, num_epochs) +\n",
    "                    'train_loss: {:.4f} - '.format(train_avg_loss[-1]) +\n",
    "                    'test_loss: {:.4f}'.format(test_avg_loss[-1]))\n",
    "\n",
    "\n",
    "            generator.eval()\n",
    "            ab_pred = generator(L_base).detach()\n",
    "            Lab_pred = torch.concat((L_base, ab_pred), 1).to(\"cpu\")\n",
    "            tensor_to_pil(Lab_pred)[0].save(\"epoch_{}.png\".format(epoch))\n",
    "            torch.save(generator.state_dict(), \"saved_models/generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Losses')\n",
    "plt.plot(train_avg_loss)\n",
    "plt.plot(test_avg_loss)\n",
    "plt.grid()\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (L1)')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the prediction of the Unet after training\n",
    "generator.eval()\n",
    "ab_pred_train = generator(L).detach()\n",
    "Lab_pred_train = torch.concat((L, ab_pred_train), 1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_pil(Lab_pred_train)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "065a011842d8ebed5411ae20512699c924712cb68d88b87277223edbfe72c920"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
