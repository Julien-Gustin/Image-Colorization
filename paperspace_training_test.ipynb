{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to train UNet with L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image\n",
    "!pip install IProgress\n",
    "!pip install jupyter\n",
    "!pip install ipywidgets widgetsnbextension pandas-profiling\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/datasets/coco\"\n",
    "version = \"2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from python.data.dataset import *\n",
    "from python.models.generator import *\n",
    "from python.utils.images import *\n",
    "from python.train.trainer import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CocoLab(dataset, version=version, size=256, train=True)\n",
    "trainloader = data.DataLoader(dataset_train, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "dataset_test = CocoLab(dataset, version=version, size=256, train=False)\n",
    "testloader = data.DataLoader(dataset_test, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "generator = UNet(1, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one image from the training set\n",
    "L_base, ab_base = next(iter(trainloader))\n",
    "\n",
    "Lab = torch.concat((L_base, ab_base), 1)\n",
    "tensor_to_pil(Lab)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the prediction of the Unet before training\n",
    "generator.eval()\n",
    "L_base = L_base.to(device)\n",
    "ab_pred_notrain = generator(L_base).detach()\n",
    "Lab_pred_notrain = torch.concat((L_base, ab_pred_notrain), 1).to(\"cpu\")\n",
    "tensor_to_pil(Lab_pred_notrain)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0002\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    generator.train()\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for L, ab in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            L = L.to(device)\n",
    "            ab = ab.to(device)\n",
    "\n",
    "            pred = generator(L)\n",
    "            loss = criterion(pred, ab)\n",
    "\n",
    "            train_losses.append(loss.detach())\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():   \n",
    "            generator.eval()\n",
    "\n",
    "            for L, ab in testloader:\n",
    "                L = L.to(device)\n",
    "                ab = ab.to(device)\n",
    "\n",
    "                pred = generator(L)\n",
    "                loss = criterion(pred, ab)\n",
    "                test_losses.append(loss.detach())\n",
    "\n",
    "            train_avg_loss.append(torch.mean(torch.Tensor(train_losses)))\n",
    "            test_avg_loss.append(torch.mean(torch.Tensor(test_losses)))\n",
    "\n",
    "            print('[Epoch {}/{}] '.format(epoch+1, num_epochs) +\n",
    "                    'train_loss: {:.4f} - '.format(train_avg_loss[-1]) +\n",
    "                    'test_loss: {:.4f}'.format(test_avg_loss[-1]))\n",
    "\n",
    "\n",
    "            generator.eval()\n",
    "            ab_pred = generator(L_base).detach()\n",
    "            Lab_pred = torch.concat((L_base, ab_pred), 1).to(\"cpu\")\n",
    "            tensor_to_pil(Lab_pred)[0].save(\"epoch_{}.png\".format(epoch))\n",
    "            torch.save(generator.state_dict(), \"saved_models/generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Losses')\n",
    "plt.plot(train_avg_loss)\n",
    "plt.plot(test_avg_loss)\n",
    "plt.grid()\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (L1)')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the prediction of the Unet after training\n",
    "generator.eval()\n",
    "ab_pred_train = generator(L).detach()\n",
    "Lab_pred_train = torch.concat((L, ab_pred_train), 1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_pil(Lab_pred_train)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "065a011842d8ebed5411ae20512699c924712cb68d88b87277223edbfe72c920"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
