{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to train UNet with L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from data.dataset import *\n",
    "from models.generator import *\n",
    "from utils.images import *\n",
    "from models.trainer import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CocoLab('/datasets/coco', version=\"2014\", size=256, train=True)\n",
    "trainloader = data.DataLoader(dataset_train, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "dataset_test = CocoLab('/datasets/coco', version=\"2014\", size=256, train=False)\n",
    "testloader = data.DataLoader(dataset_test, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "generator = UNet(1, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one image from the training set\n",
    "L_base, ab_base = next(iter(trainloader))\n",
    "\n",
    "Lab = torch.concat((L_base, ab_base), 1)\n",
    "tensor_to_pil(Lab)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the prediction of the Unet before training\n",
    "generator.eval()\n",
    "L_base = L_base.to(device)\n",
    "ab_pred_notrain = generator(L_base).detach()\n",
    "Lab_pred_notrain = torch.concat((L_base, ab_pred_notrain), 1)\n",
    "tensor_to_pil(Lab_pred_notrain)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "display_every = 10\n",
    "# train_avg_loss, test_avg_loss = train_G_L1(epochs, generator, loader_train, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_avg_loss = []\n",
    "test_avg_loss = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    generator.train()\n",
    "    for L, ab in trainloader:\n",
    "        L = L.to(device)\n",
    "        ab = ab.to(device)\n",
    "\n",
    "        pred = generator(L)\n",
    "        loss = criterion(pred, ab)\n",
    "\n",
    "        train_losses.append(loss.detach())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():   \n",
    "        generator.eval()\n",
    "        total = 0\n",
    "\n",
    "        for L, ab in testloader:\n",
    "            L = L.to(device)\n",
    "            ab = ab.to(device)\n",
    "            \n",
    "            pred = generator(L)\n",
    "            loss = criterion(pred, ab)\n",
    "            test_losses.append(loss.detach())\n",
    "\n",
    "            total += len(pred)\n",
    "\n",
    "        print(total)\n",
    "\n",
    "        train_avg_loss.append(torch.mean(torch.Tensor(train_losses)))\n",
    "        test_avg_loss.append(torch.mean(torch.Tensor(test_losses)))\n",
    "\n",
    "        print('[Epoch {}/{}] '.format(i+1, num_epochs) +\n",
    "                'train_loss: {:.4f} - '.format(train_avg_loss[-1]) +\n",
    "                'test_loss: {:.4f}'.format(test_avg_loss[-1]))\n",
    "\n",
    "\n",
    "        if i % display_every:\n",
    "            generator.eval()\n",
    "            ab_pred = generator(L_base).detach()\n",
    "            Lab_pred = torch.concat((L_base, ab_pred), 1)\n",
    "            tensor_to_pil(Lab_pred)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Losses')\n",
    "plt.plot(train_avg_loss)\n",
    "plt.plot(test_avg_loss)\n",
    "plt.grid()\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (L1)')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the prediction of the Unet after training\n",
    "generator.eval()\n",
    "ab_pred_train = generator(L).detach()\n",
    "Lab_pred_train = torch.concat((L, ab_pred_train), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_pil(Lab_pred_train)[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "065a011842d8ebed5411ae20512699c924712cb68d88b87277223edbfe72c920"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
